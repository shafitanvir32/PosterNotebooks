{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9894567,"sourceType":"datasetVersion","datasetId":6077294},{"sourceId":206527397,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import DistilBertTokenizer, BertForSequenceClassification\nimport torch\n\n# Load the default tokenizer from Hugging Face\ntokenizer = DistilBertTokenizer.from_pretrained('shafitanvir31/bangla-bert-finetuned-sagor2')\n\n# Load the fine-tuned model from Hugging Face\nmodel = BertForSequenceClassification.from_pretrained('shafitanvir31/bangla-bert-finetuned-sagor2')\n\n# Move model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\nprint(\"Model and tokenizer loaded successfully with the default tokenizer!\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nnew_df = pd.read_csv('/kaggle/input/test-dataset354/modified_dataset (2).csv')\n\n# Preview the dataset\nprint(new_df.head())\nprint('Number of samples:', new_df.shape[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:17.410846Z","iopub.execute_input":"2024-11-13T14:33:17.411192Z","iopub.status.idle":"2024-11-13T14:33:17.436195Z","shell.execute_reply.started":"2024-11-13T14:33:17.411134Z","shell.execute_reply":"2024-11-13T14:33:17.435317Z"}},"outputs":[{"name":"stdout","text":"   ID                                              TITLE               SOURCE  \\\n0   1                            খেজুরবাগানে গুড় সম্মেলন          prothom alo   \n1   2  টয়লেটে মুঠোফোন চালিয়ে পাইলসের ঝুঁকি বাড়াচ্ছেন ...          prothom alo   \n2   3            ফারুকীকে অভিনন্দন জানিয়ে কী লিখলেন তিশা          prothom alo   \n3   4  খুন হওয়ার আশঙ্কা করে ভাষণ দেওয়ার পরদিন ২৮ গুলি...          prothom alo   \n4   5                             দীর্ঘ হচ্ছে লাশের সারি  bangladesh protidin   \n\n                                             ARTICLE  LABEL          TOPIC  \\\n0  সকালে অতিথিদের আপ্যায়নে ছিল খেজুরের রস। পরে চা...      1     enviroment   \n1  মোডে বসে মুঠোফোন চালালে যা হয়এতে দুটি বিষয় ঘটে...      1        general   \n2  অন্তর্বর্তী সরকারের উপদেষ্টা হিসেবে শপথ নিলেন ...      1  entertainment   \n3  ভারতের প্রভাবশালী রাজনৈতিক পরিবারে তাঁর জন্ম। ...      1       politics   \n4  ডেঙ্গুজ্বরে আক্রান্ত হয়ে সারা দেশের হাসপাতালে ...      1         health   \n\n   YEAR          BASE  \n0   NaN  Common Sense  \n1   NaN  Common Sense  \n2   NaN  Common Sense  \n3   NaN  Common Sense  \n4   NaN  Common Sense  \nNumber of samples: 100\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Merge TITLE and ARTICLE columns\nnew_df['news'] = new_df['TITLE'] + ' ' + new_df['ARTICLE']\n\n# Check for any missing values in the 'news' column\nprint(new_df['news'].isnull().sum())\n\n# If there are missing values, you might want to handle them\n# For example, fill NaN values with empty strings\nnew_df['news'] = new_df['news'].fillna('')\n\n# Preview the 'news' column\nprint(new_df[['news']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:17.437805Z","iopub.execute_input":"2024-11-13T14:33:17.438270Z","iopub.status.idle":"2024-11-13T14:33:17.447526Z","shell.execute_reply.started":"2024-11-13T14:33:17.438220Z","shell.execute_reply":"2024-11-13T14:33:17.446482Z"}},"outputs":[{"name":"stdout","text":"0\n                                                news\n0  খেজুরবাগানে গুড় সম্মেলন সকালে অতিথিদের আপ্যায়ন...\n1  টয়লেটে মুঠোফোন চালিয়ে পাইলসের ঝুঁকি বাড়াচ্ছেন ...\n2  ফারুকীকে অভিনন্দন জানিয়ে কী লিখলেন তিশা অন্তর্...\n3  খুন হওয়ার আশঙ্কা করে ভাষণ দেওয়ার পরদিন ২৮ গুলি...\n4  দীর্ঘ হচ্ছে লাশের সারি ডেঙ্গুজ্বরে আক্রান্ত হয়...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def tokenize_and_split(text, tokenizer, max_length):\n    # Tokenize the text\n    tokens = tokenizer.tokenize(text)\n    \n    # Account for [CLS] and [SEP] with \"- 2\"\n    if len(tokens) > max_length - 2:\n        # Split the tokens into chunks of size max_length - 2\n        chunks = [tokens[i:i + (max_length - 2)] for i in range(0, len(tokens), max_length - 2)]\n    else:\n        chunks = [tokens]\n    \n    return chunks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:17.450653Z","iopub.execute_input":"2024-11-13T14:33:17.451082Z","iopub.status.idle":"2024-11-13T14:33:17.457530Z","shell.execute_reply.started":"2024-11-13T14:33:17.451036Z","shell.execute_reply":"2024-11-13T14:33:17.456689Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def prepare_inference_data(df, tokenizer, max_length):\n    input_ids = []\n    attention_masks = []\n    article_ids = []  # To keep track of which chunks belong to which article\n    \n    for idx, row in df.iterrows():\n        text = row['news']\n        \n        # Handle possible NaN values\n        if pd.isna(text):\n            text = ''\n        \n        chunks = tokenize_and_split(text, tokenizer, max_length)\n        \n        for chunk in chunks:\n            # Reconstruct the chunk back to a string\n            chunk_text = tokenizer.convert_tokens_to_string(chunk)\n            \n            # Encode the chunk\n            encoding = tokenizer.encode_plus(\n                chunk_text,\n                add_special_tokens=True,\n                max_length=max_length,\n                padding='max_length',\n                truncation=True,\n                return_attention_mask=True,\n                return_tensors='pt',\n            )\n            \n            input_ids.append(encoding['input_ids'])\n            attention_masks.append(encoding['attention_mask'])\n            article_ids.append(idx)  # Keep track of the article ID\n    \n    # Convert lists to tensors\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    article_ids = torch.tensor(article_ids)\n    \n    return input_ids, attention_masks, article_ids\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:17.458642Z","iopub.execute_input":"2024-11-13T14:33:17.458963Z","iopub.status.idle":"2024-11-13T14:33:17.467539Z","shell.execute_reply.started":"2024-11-13T14:33:17.458930Z","shell.execute_reply":"2024-11-13T14:33:17.466649Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"MAX_LEN = 512  # Use the same MAX_LEN as during training\n# Prepare the data for inference\ninput_ids, attention_masks, article_ids = prepare_inference_data(new_df, tokenizer, MAX_LEN)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:17.468650Z","iopub.execute_input":"2024-11-13T14:33:17.469007Z","iopub.status.idle":"2024-11-13T14:33:19.724952Z","shell.execute_reply.started":"2024-11-13T14:33:17.468964Z","shell.execute_reply":"2024-11-13T14:33:19.724186Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n\n# Create the dataset\ninference_dataset = TensorDataset(input_ids, attention_masks, article_ids)\n\n# Create DataLoader\nbatch_size = 4  # Adjust based on your GPU memory\ninference_dataloader = DataLoader(inference_dataset, sampler=SequentialSampler(inference_dataset), batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:19.725993Z","iopub.execute_input":"2024-11-13T14:33:19.726299Z","iopub.status.idle":"2024-11-13T14:33:19.733416Z","shell.execute_reply.started":"2024-11-13T14:33:19.726266Z","shell.execute_reply":"2024-11-13T14:33:19.732459Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import numpy as np\nmodel.eval()\n\n# Tracking variables \narticle_predictions = {}\n\nfor batch in inference_dataloader:\n    # Unpack the inputs from the dataloader\n    b_input_ids = batch[0].to(device)\n    b_attention_mask = batch[1].to(device)\n    b_article_ids = batch[2].to('cpu').numpy()\n    \n    with torch.no_grad():\n        outputs = model(b_input_ids,\n                        attention_mask=b_attention_mask)\n        \n        logits = outputs.logits\n    \n    logits = logits.detach().cpu().numpy()\n    preds = np.argmax(logits, axis=1)\n    \n    for article_id, pred in zip(b_article_ids, preds):\n        article_id = int(article_id)\n        if article_id not in article_predictions:\n            article_predictions[article_id] = []\n        article_predictions[article_id].append(pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:19.734504Z","iopub.execute_input":"2024-11-13T14:33:19.734843Z","iopub.status.idle":"2024-11-13T14:33:23.649924Z","shell.execute_reply.started":"2024-11-13T14:33:19.734804Z","shell.execute_reply":"2024-11-13T14:33:23.648962Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Aggregate predictions per article\nfinal_predictions = []\n\nfor idx in range(len(new_df)):\n    preds = article_predictions.get(idx, [0])  # Default to class '0' if no prediction is available\n    # Majority vote\n    final_pred = max(set(preds), key=preds.count)\n    final_predictions.append(final_pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:23.651198Z","iopub.execute_input":"2024-11-13T14:33:23.651506Z","iopub.status.idle":"2024-11-13T14:33:23.656700Z","shell.execute_reply.started":"2024-11-13T14:33:23.651474Z","shell.execute_reply":"2024-11-13T14:33:23.655699Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Add the predictions to the DataFrame\nnew_df['PREDICTION'] = final_predictions\n\n# Map numeric predictions to class labels if needed\n# For example, if your labels are 0 and 1, and you want to map them to 'Fake' and 'Real':\n# label_mapping = {0: 'Fake', 1: 'Real'}\n# new_df['PREDICTION_LABEL'] = new_df['PREDICTION'].map(label_mapping)\n\n# Preview the DataFrame with predictions\nprint(new_df[['ID', 'TITLE', 'PREDICTION']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:23.661328Z","iopub.execute_input":"2024-11-13T14:33:23.661707Z","iopub.status.idle":"2024-11-13T14:33:23.825749Z","shell.execute_reply.started":"2024-11-13T14:33:23.661669Z","shell.execute_reply":"2024-11-13T14:33:23.824658Z"}},"outputs":[{"name":"stdout","text":"   ID                                              TITLE  PREDICTION\n0   1                            খেজুরবাগানে গুড় সম্মেলন           0\n1   2  টয়লেটে মুঠোফোন চালিয়ে পাইলসের ঝুঁকি বাড়াচ্ছেন ...           1\n2   3            ফারুকীকে অভিনন্দন জানিয়ে কী লিখলেন তিশা           1\n3   4  খুন হওয়ার আশঙ্কা করে ভাষণ দেওয়ার পরদিন ২৮ গুলি...           0\n4   5                             দীর্ঘ হচ্ছে লাশের সারি           1\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Specify the output file path\noutput_file_path = '/kaggle/working/predicted_dataset.csv'\n\n# Save the DataFrame to CSV\nnew_df.to_csv(output_file_path, index=False)\n\nprint(f\"Dataset with predictions saved to {output_file_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:23.827379Z","iopub.execute_input":"2024-11-13T14:33:23.827928Z","iopub.status.idle":"2024-11-13T14:33:23.851649Z","shell.execute_reply.started":"2024-11-13T14:33:23.827870Z","shell.execute_reply":"2024-11-13T14:33:23.850794Z"}},"outputs":[{"name":"stdout","text":"Dataset with predictions saved to /kaggle/working/predicted_dataset.csv\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"final_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T14:33:23.852763Z","iopub.execute_input":"2024-11-13T14:33:23.853045Z","iopub.status.idle":"2024-11-13T14:33:23.861163Z","shell.execute_reply.started":"2024-11-13T14:33:23.853014Z","shell.execute_reply":"2024-11-13T14:33:23.860199Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0]"},"metadata":{}}],"execution_count":26}]}